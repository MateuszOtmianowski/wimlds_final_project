{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon S3 - Simple Storage Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During todays workshop we will focus on practical usage of S3. There are three main methods of accessing Amazon S3:\n",
    "- AWS Management Console\n",
    "- AWS CLI\n",
    "- Boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    AWS Management Console\n",
    "AWS Management Console lets you access and manage AWS through a simple and intuitive web-based user interface.\n",
    "\n",
    "Tasks to complete in this subsection:\n",
    "- show buckets\n",
    "- list objects in a bucket\n",
    "- operations on files\n",
    "    - downloading\n",
    "    - uploading\n",
    "- getting familiar with bucket properties\n",
    "- getting familiar with bucket permissions\n",
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show buckets, list objects in a bucket \n",
    "\n",
    "A. Go to [AWS console](https://eu-west-1.console.aws.amazon.com/console/home?nc2=h_ct&region=eu-west-1&src=header-signin#) and login.\n",
    "\n",
    "B. Choose: \n",
    ">Services\n",
    "\n",
    "<img src=\"img/02.png\" width=\"900\">\n",
    "\n",
    "\n",
    "C. Choose: \n",
    "> S3 \n",
    "\n",
    "<img src=\"img/03.png\" width=\"900\">\n",
    "\n",
    "D. Choose a bucket whose content you would like to display, for example:\n",
    "> staging-dir-wimlds-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations on files\n",
    "Downloading:\n",
    "- mark file \n",
    "- \"Actions\" \n",
    "- \"Download as\"\n",
    "    \n",
    "Uploading:\n",
    "- \"Upload\"\n",
    "- Drag and drop or provide directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket properties\n",
    "- __versioning:__ keep multiple versions of an object in one bucket. This feauture protects you from the consequences of unintended overwrites and deletions\n",
    "- __server access logging:__ detailed records for the requests that are made to a bucket\n",
    "- __static website hosting:__ host a static website \n",
    "- __object-level logging:__ data events provide insight into the resource operations performed on or within a resource\n",
    "- __default encryption:__ provides a way to set the default encryption behavior for an S3 bucket. You can set default encryption on a bucket so that all objects are encrypted when they are stored in the bucket. The objects are encrypted using server-side encryption with either Amazon S3-managed keys (SSE-S3) or AWS KMS-managed keys (SSE-KMS)\n",
    "- __object lock:__ store objects using a \"Write Once Read Many\" (WORM) model\n",
    "- __tags:__ track the storage cost or other criteria for individual projects or groups of projects\n",
    "- __transfer acceleration:__ fast transfer of files over long distances between client and an S3 bucket\n",
    "- __events:__ enable certain Amazon S3 bucket events to send a notification message to a destination whenever the events occur\n",
    "- __requester pays:__ the requester instead of the bucket owner pays the cost of the request and the data download from the bucket\n",
    "\n",
    " \n",
    "<img src=\"img/04.png\" width=\"900\">\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bucket permissions\n",
    "- __public access settings:__ whether data can be accessed publicly \n",
    "- __access control list:__ decide who and what may see\n",
    "- __bucket policy:__ decide what actions may be done and by who\n",
    "\n",
    "<img src=\"img/05.png\" width=\"1000\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise (2 minutes)\n",
    "1. Create a bucket.\n",
    "2. Select the bucket you have created and upload titanic.csv file there.\n",
    "3. Add tags to the file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    AWS CLI \n",
    "The AWS Command Line Interface (CLI) is a unified tool to manage AWS services. Enable controlling multiple AWS services from the command line and automate them through scripts.\n",
    "\n",
    "Tasks to complete in this subsection:\n",
    "- prerequisities\n",
    "    - AWS CLI installation\n",
    "    - get the access key\n",
    "    - configure AWS profile\n",
    "- getting familiar with S3 commands\n",
    "- run commands:\n",
    "    - ls\n",
    "    - cp\n",
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install AWS CLI \n",
    "- Windows \n",
    "    Download and run the 64-bit or 32-bit Windows installer (website)\n",
    "    \n",
    "[Here you will find files if you use windows](https://aws.amazon.com/cli/)\n",
    "\n",
    "- Mac and linux \n",
    "\n",
    "    `[sudo] pip3 install awscli`\n",
    "\n",
    "#### Generate access key and secret access key\n",
    "\n",
    "- [Instruction](https://help.bittitan.com/hc/en-us/articles/115008255268-How-do-I-find-my-AWS-Access-Key-and-Secret-Access-Key-)\n",
    "\n",
    "\n",
    "#### Create AWS profile on your local machine\n",
    "- Type in terminal:\n",
    "\n",
    "    `aws --profile <profile_name> configure`\n",
    "    \n",
    "    for example\n",
    "    \n",
    "    `aws --profile wimlds configure`\n",
    "\n",
    "\n",
    "- You have to provide your access key, secret acces key (generated in the previous step) and region\n",
    "\n",
    "<img src=\"img/06.png\" width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available commands\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cp` copy \n",
    "\n",
    "`ls` list objects\n",
    "\n",
    "`mb` create empty bucket\n",
    "\n",
    "`mv` move\n",
    "\n",
    "`presign` generates URL adress for an object\n",
    "\n",
    "`rb` delete empty bucket\n",
    "\n",
    "`rm` delete object\n",
    "\n",
    "`sync` syncs directories and s3 prefixes, recursive copies from the source directory to the destination\n",
    "\n",
    "`website` set the website configuration for a bucket - creates static website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "`ls` list buckets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws --profile wimlds s3 ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ls` list objects in the given bucket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws --profile wimlds  s3 ls s3://staging-dir-wimlds-workshop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cp` copy [Flags](https://docs.aws.amazon.com/cli/latest/reference/s3/cp.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From S3 to local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws --profile wimlds s3 cp s3://staging-dir-wimlds-workshop/titanic.csv <local_directory_where_you_want_to_save_a_file>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From local to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! aws --profile wimlds s3 cp <file_to_upload_directory> s3://staging-dir-wimlds-workshop/titanic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 (5 minutes)\n",
    "\n",
    "Goal: Create a new bucket and upload a file. Then create an URL adress and copy object from your browser.\n",
    "\n",
    "1. List available buckets.\n",
    "2. Create a new bucket.\n",
    "3. List available bucket (double check).\n",
    "4. Copy local file to S3.\n",
    "5. Create URL adress.\n",
    "6. Copy and paste adress to your web browser.\n",
    "7. Download file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python boto3\n",
    "Boto is the Amazon Web Services (AWS) SDK for Python, which allows Python developers to write software that makes use of Amazon services like S3 and EC2. Boto provides an easy to use, object-oriented API as well as low-level direct service access.\n",
    "\n",
    "Tasks to complete in this subsection:\n",
    "- prerequisities\n",
    "    - boto3 installation\n",
    "    - boto3 documentation\n",
    "- getting familiar with boto 3\n",
    "- list buckets\n",
    "- list objects in a given bucket\n",
    "- exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerquisities\n",
    "\n",
    "#### Install boto3\n",
    "- Go to terminal and type\n",
    "\n",
    "    `pip install boto3`\n",
    "\n",
    "    if does not work\n",
    "    \n",
    "    `pip3 install boto3`\n",
    "\n",
    "    or \n",
    "\n",
    "    `sudo pip3 install boto3`\n",
    "\n",
    "- [Boto 3 Documentation](https://boto3.amazonaws.com/v1/documentation/api/latest/index.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create an object of a class you want to work with. Two main classes are:\n",
    "- client (low-level)\n",
    "- resource (higher-level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Create a session`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "profile_name = 'wimlds'\n",
    "session = boto3.session.Session(profile_name=profile_name)\n",
    "s3 = session.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list buckets`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List buckets\n",
    "s3_buckets = s3.list_buckets()\n",
    "for bucket in s3_buckets['Buckets']:\n",
    "    print(bucket['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`list objects in the given bucket`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List objects in the bucket\n",
    "bucket_name = 'staging-dir-wimlds-workshop'\n",
    "s3_objects = s3.list_objects(Bucket = bucket_name)\n",
    "for object in s3_objects['Contents']:\n",
    "    print(\"Filename {} of size {} kB\".format(object['Key'], object['Size']/1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 (3 minutes)\n",
    "\n",
    "Goal: Send file to S3 using boto3. \n",
    "\n",
    "Protip: You may/should :) use boto3 documentation\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
